{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as preprocess_input_vgg19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input as preprocess_input_resnet50\n",
    "\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.core import Dropout, Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "import datetime\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input as preprocess_input_Xception\n",
    "from keras.models import load_model\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection automatique d'angle (brouillon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook implémente une ébauche d'algorithme de détection automatique d'angles entre -pi/5 et +pi/5. On sélectionne le meilleur hyperparamètre\n",
    "(ici dropout pour la régularisation, taille des mini-batchs et nombre de neurones sur les couches ajoutées) sur le jeu de validation en visualisant l'évolution de la fonction de cout. On quantifie la performances via une RMSE sur jeu de test. On utilise ensuite les angles détectés pour créer des images dont le cadre est incliné de l'opposé de cet angle. Le contenu de l'image est, quand à lui, devenu droit. On utilise une fonction d'activation softmax sur le dernier neurone représentant l'angle redimmensionné entre 0 et 1 (0 correspondant à un angle de -pi/5 rad et 1, +pi/5 rad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_Xception = 299\n",
    "\n",
    "# ouvrir le fichier \n",
    "\n",
    "labels = pd.read_csv('liste_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((nb_train,dim_Xception,dim_Xception,3),dtype=np.float32)\n",
    "\n",
    "y_train = np.zeros(nb_train)\n",
    "\n",
    "X_test = np.zeros((nb_test,dim_Xception,ddim_Xception,3),dtype=np.float32)\n",
    "\n",
    "y_test = np.zeros(nb_test)\n",
    "\n",
    "\n",
    "X_valid = np.zeros((nb_valid,dim_Xception,dim_Xception,3),dtype=np.float32)\n",
    "\n",
    "y_valid = np.zeros(nb_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_valid = 0\n",
    "\n",
    "# Open a file\n",
    "path = \"./images_t/valid/\"\n",
    "dirs = os.listdir( path )\n",
    "\n",
    "for file in (dirs):\n",
    "    #index = file.find('g')     \n",
    "        \n",
    "    y_valid[j_valid] = float(labels[labels['name'] == str(file)].iloc[0,2][1:-1])\n",
    "    if (file[0] == 'l'):\n",
    "        \n",
    "        y_valid[j_valid] = -y_valid[j_valid]\n",
    "    \n",
    "    #print (y_valid[j_valid,:])\n",
    "        \n",
    "    file_picture = \"./images_t/valid/\" + str(file)\n",
    "     \n",
    "    #img = Image.open(file_picture)\n",
    "    #img.thumbnail((224, 224))\n",
    "    \n",
    "    img = load_img(file_picture, target_size=(299, 299))  # this is a PIL image \n",
    "    matrix = img_to_array(img)\n",
    "    X_valid[j_valid,:,:,:] = matrix[:,:,:]\n",
    "        \n",
    "    j_valid = j_valid + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_test = 0\n",
    "\n",
    "# Open a file\n",
    "path = \"./images_t/te/\"\n",
    "dirs = os.listdir( path )\n",
    "\n",
    "for file in (dirs):\n",
    "    #index = file.find('g')     \n",
    "        \n",
    "    y_test[j_test] = float(labels[labels['name'] == str(file)].iloc[0,2][1:-1])\n",
    "    if (file[0] == 'l'):\n",
    "        \n",
    "        y_test[j_test] = -y_test[j_test]\n",
    "    \n",
    "    #print (y_valid[j_valid,:])\n",
    "        \n",
    "    file_picture = \"./images_t/tr/\" + str(file)\n",
    "     \n",
    "    #img = Image.open(file_picture)\n",
    "    #img.thumbnail((224, 224))\n",
    "    \n",
    "    img = load_img(file_picture, target_size=(299, 299))  # this is a PIL image \n",
    "    matrix = img_to_array(img)\n",
    "    X_test[j_test,:,:,:] = matrix[:,:,:]\n",
    "        \n",
    "    j_test = j_test + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_train = 0\n",
    "\n",
    "# Open a file\n",
    "path = \"./images_t/tr/\"\n",
    "dirs = os.listdir( path )\n",
    "\n",
    "for file in (dirs):\n",
    "    #index = file.find('g')     \n",
    "        \n",
    "    y_train[j_train] = float(labels[labels['name'] == str(file)].iloc[0,2][1:-1])\n",
    "    if (file[0] == 'l'):\n",
    "        \n",
    "        y_train[j_train] = -y_train[j_train]\n",
    "    \n",
    "    #print (y_valid[j_valid,:])\n",
    "        \n",
    "    file_picture = \"./images_t/tr/\" + str(file)\n",
    "     \n",
    "    #img = Image.open(file_picture)\n",
    "    #img.thumbnail((224, 224))\n",
    "    \n",
    "    img = load_img(file_picture, target_size=(299, 299))  # this is a PIL image \n",
    "    matrix = img_to_array(img)\n",
    "    X_train[j_train,:,:,:] = matrix[:,:,:]\n",
    "        \n",
    "    j_train = j_train + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaling between 0 and 1 \n",
    "y_test[:] = 1 + y_test[:]/30\n",
    "y_train[:] = 1 + y_train[:]/30\n",
    "y_valid[:] = 1 + y_valid[:]/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "imput_train_Xception = preprocess_input_Xception(X_train)\n",
    "train_Xception = Xception(weights='imagenet', include_top=False).predict(imput_train_Xception)\n",
    "\n",
    "print ('done')\n",
    "\n",
    "imput_test_Xception = preprocess_input_Xception(X_test.copy())\n",
    "test_Xception = Xception(weights='imagenet', include_top=False).predict(imput_test_Xception)\n",
    "\n",
    "print ('done')\n",
    "\n",
    "imput_valid_Xception = preprocess_input_Xception(X_valid)\n",
    "valid_Xception = Xception(weights='imagenet', include_top=False).predict(imput_valid_Xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 10, 10, 2048)      0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1048576   \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 1,580,033\n",
      "Trainable params: 1,576,961\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def input_branch(input_shape=None):\n",
    "    \n",
    "    size = int(input_shape[2] / 4)\n",
    "    \n",
    "    branch_input = Input(shape=input_shape)\n",
    "    branch = GlobalAveragePooling2D()(branch_input)\n",
    "    branch = Dense(size, use_bias=False, kernel_initializer='uniform')(branch)\n",
    "    branch = BatchNormalization()(branch)\n",
    "    branch = Activation(\"relu\")(branch)\n",
    "    return branch, branch_input\n",
    "\n",
    "Xception_branch, Xception_input = input_branch(input_shape=(10, 10, 2048))\n",
    "\n",
    "\n",
    "net = Dropout(0.34)(Xception_branch)\n",
    "net = Dense(1024, use_bias=False, kernel_initializer='uniform')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Activation(\"relu\")(net)\n",
    "net = Dropout(0.34)(net)\n",
    "net = Dense(1, kernel_initializer='uniform', activation=\"sigmoid\")(net)\n",
    "\n",
    "model = Model(inputs=[Xception_input], outputs=[net])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5)\n",
    "STAMP = \"{}_dog_breed_model\".format(datetime.date.today().strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "bst_model_path = \"./models/{}.h5\".format(STAMP)\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19012 samples, validate on 5104 samples\n",
      "Epoch 1/100\n",
      " - 27s - loss: 0.2308 - mean_absolute_error: 0.4152 - val_loss: 0.2313 - val_mean_absolute_error: 0.4144\n",
      "Epoch 2/100\n",
      " - 25s - loss: 0.2290 - mean_absolute_error: 0.4133 - val_loss: 0.2315 - val_mean_absolute_error: 0.4139\n",
      "Epoch 3/100\n",
      " - 25s - loss: 0.2276 - mean_absolute_error: 0.4116 - val_loss: 0.2310 - val_mean_absolute_error: 0.4131\n",
      "Epoch 4/100\n",
      " - 25s - loss: 0.2269 - mean_absolute_error: 0.4109 - val_loss: 0.2308 - val_mean_absolute_error: 0.4122\n",
      "Epoch 5/100\n",
      " - 25s - loss: 0.2262 - mean_absolute_error: 0.4097 - val_loss: 0.2316 - val_mean_absolute_error: 0.4108\n",
      "Epoch 6/100\n",
      " - 25s - loss: 0.2248 - mean_absolute_error: 0.4075 - val_loss: 0.2293 - val_mean_absolute_error: 0.4076\n",
      "Epoch 7/100\n",
      " - 25s - loss: 0.2240 - mean_absolute_error: 0.4063 - val_loss: 0.2269 - val_mean_absolute_error: 0.4055\n",
      "Epoch 8/100\n",
      " - 25s - loss: 0.2228 - mean_absolute_error: 0.4043 - val_loss: 0.2247 - val_mean_absolute_error: 0.4016\n",
      "Epoch 9/100\n",
      " - 25s - loss: 0.2209 - mean_absolute_error: 0.4017 - val_loss: 0.2252 - val_mean_absolute_error: 0.3996\n",
      "Epoch 10/100\n",
      " - 25s - loss: 0.2201 - mean_absolute_error: 0.4005 - val_loss: 0.2274 - val_mean_absolute_error: 0.3973\n",
      "Epoch 11/100\n",
      " - 25s - loss: 0.2184 - mean_absolute_error: 0.3980 - val_loss: 0.2229 - val_mean_absolute_error: 0.3949\n",
      "Epoch 12/100\n",
      " - 25s - loss: 0.2173 - mean_absolute_error: 0.3968 - val_loss: 0.2215 - val_mean_absolute_error: 0.3912\n",
      "Epoch 13/100\n",
      " - 25s - loss: 0.2159 - mean_absolute_error: 0.3946 - val_loss: 0.2252 - val_mean_absolute_error: 0.3899\n",
      "Epoch 14/100\n",
      " - 25s - loss: 0.2149 - mean_absolute_error: 0.3928 - val_loss: 0.2169 - val_mean_absolute_error: 0.3890\n",
      "Epoch 15/100\n",
      " - 25s - loss: 0.2138 - mean_absolute_error: 0.3917 - val_loss: 0.2200 - val_mean_absolute_error: 0.3861\n",
      "Epoch 16/100\n",
      " - 25s - loss: 0.2113 - mean_absolute_error: 0.3887 - val_loss: 0.2243 - val_mean_absolute_error: 0.3862\n",
      "Epoch 17/100\n",
      " - 24s - loss: 0.2096 - mean_absolute_error: 0.3862 - val_loss: 0.2155 - val_mean_absolute_error: 0.3837\n",
      "Epoch 18/100\n",
      " - 25s - loss: 0.2095 - mean_absolute_error: 0.3860 - val_loss: 0.2135 - val_mean_absolute_error: 0.3838\n",
      "Epoch 19/100\n",
      " - 24s - loss: 0.2077 - mean_absolute_error: 0.3835 - val_loss: 0.2173 - val_mean_absolute_error: 0.3817\n",
      "Epoch 20/100\n",
      " - 24s - loss: 0.2064 - mean_absolute_error: 0.3822 - val_loss: 0.2211 - val_mean_absolute_error: 0.3821\n",
      "Epoch 21/100\n",
      " - 25s - loss: 0.2047 - mean_absolute_error: 0.3798 - val_loss: 0.2124 - val_mean_absolute_error: 0.3781\n",
      "Epoch 22/100\n",
      " - 24s - loss: 0.2047 - mean_absolute_error: 0.3796 - val_loss: 0.2149 - val_mean_absolute_error: 0.3774\n",
      "Epoch 23/100\n",
      " - 23s - loss: 0.2025 - mean_absolute_error: 0.3777 - val_loss: 0.2218 - val_mean_absolute_error: 0.3782\n",
      "Epoch 24/100\n",
      " - 21s - loss: 0.2009 - mean_absolute_error: 0.3753 - val_loss: 0.2115 - val_mean_absolute_error: 0.3761\n",
      "Epoch 25/100\n",
      " - 21s - loss: 0.2009 - mean_absolute_error: 0.3752 - val_loss: 0.2107 - val_mean_absolute_error: 0.3745\n",
      "Epoch 26/100\n",
      " - 21s - loss: 0.1995 - mean_absolute_error: 0.3732 - val_loss: 0.2103 - val_mean_absolute_error: 0.3730\n",
      "Epoch 27/100\n",
      " - 21s - loss: 0.1979 - mean_absolute_error: 0.3715 - val_loss: 0.2063 - val_mean_absolute_error: 0.3718\n",
      "Epoch 28/100\n",
      " - 21s - loss: 0.1967 - mean_absolute_error: 0.3701 - val_loss: 0.2090 - val_mean_absolute_error: 0.3699\n",
      "Epoch 29/100\n",
      " - 21s - loss: 0.1965 - mean_absolute_error: 0.3705 - val_loss: 0.2157 - val_mean_absolute_error: 0.3725\n",
      "Epoch 30/100\n",
      " - 21s - loss: 0.1953 - mean_absolute_error: 0.3682 - val_loss: 0.2049 - val_mean_absolute_error: 0.3709\n",
      "Epoch 31/100\n",
      " - 22s - loss: 0.1939 - mean_absolute_error: 0.3668 - val_loss: 0.2065 - val_mean_absolute_error: 0.3672\n",
      "Epoch 32/100\n",
      " - 22s - loss: 0.1926 - mean_absolute_error: 0.3648 - val_loss: 0.2054 - val_mean_absolute_error: 0.3670\n",
      "Epoch 33/100\n",
      " - 22s - loss: 0.1928 - mean_absolute_error: 0.3650 - val_loss: 0.2141 - val_mean_absolute_error: 0.3696\n",
      "Epoch 34/100\n",
      " - 22s - loss: 0.1904 - mean_absolute_error: 0.3618 - val_loss: 0.2163 - val_mean_absolute_error: 0.3679\n",
      "Epoch 35/100\n",
      " - 22s - loss: 0.1899 - mean_absolute_error: 0.3610 - val_loss: 0.2108 - val_mean_absolute_error: 0.3643\n",
      "Epoch 36/100\n",
      " - 22s - loss: 0.1887 - mean_absolute_error: 0.3597 - val_loss: 0.2066 - val_mean_absolute_error: 0.3635\n",
      "Epoch 37/100\n",
      " - 22s - loss: 0.1885 - mean_absolute_error: 0.3597 - val_loss: 0.2128 - val_mean_absolute_error: 0.3641\n",
      "Epoch 38/100\n",
      " - 22s - loss: 0.1882 - mean_absolute_error: 0.3592 - val_loss: 0.2034 - val_mean_absolute_error: 0.3631\n",
      "Epoch 39/100\n",
      " - 22s - loss: 0.1864 - mean_absolute_error: 0.3571 - val_loss: 0.2150 - val_mean_absolute_error: 0.3641\n",
      "Epoch 40/100\n",
      " - 22s - loss: 0.1866 - mean_absolute_error: 0.3567 - val_loss: 0.2082 - val_mean_absolute_error: 0.3623\n",
      "Epoch 41/100\n",
      " - 23s - loss: 0.1869 - mean_absolute_error: 0.3575 - val_loss: 0.2101 - val_mean_absolute_error: 0.3624\n",
      "Epoch 42/100\n",
      " - 23s - loss: 0.1852 - mean_absolute_error: 0.3556 - val_loss: 0.2077 - val_mean_absolute_error: 0.3609\n",
      "Epoch 43/100\n",
      " - 22s - loss: 0.1839 - mean_absolute_error: 0.3536 - val_loss: 0.2217 - val_mean_absolute_error: 0.3648\n",
      "Epoch 44/100\n",
      " - 22s - loss: 0.1841 - mean_absolute_error: 0.3534 - val_loss: 0.2150 - val_mean_absolute_error: 0.3641\n",
      "Epoch 45/100\n",
      " - 22s - loss: 0.1828 - mean_absolute_error: 0.3518 - val_loss: 0.2002 - val_mean_absolute_error: 0.3583\n",
      "Epoch 46/100\n",
      " - 22s - loss: 0.1819 - mean_absolute_error: 0.3510 - val_loss: 0.2239 - val_mean_absolute_error: 0.3649\n",
      "Epoch 47/100\n",
      " - 22s - loss: 0.1820 - mean_absolute_error: 0.3511 - val_loss: 0.2037 - val_mean_absolute_error: 0.3561\n",
      "Epoch 48/100\n",
      " - 22s - loss: 0.1806 - mean_absolute_error: 0.3494 - val_loss: 0.2099 - val_mean_absolute_error: 0.3570\n",
      "Epoch 49/100\n",
      " - 22s - loss: 0.1800 - mean_absolute_error: 0.3484 - val_loss: 0.2075 - val_mean_absolute_error: 0.3558\n",
      "Epoch 50/100\n",
      " - 22s - loss: 0.1798 - mean_absolute_error: 0.3478 - val_loss: 0.2269 - val_mean_absolute_error: 0.3652\n",
      "Epoch 51/100\n",
      " - 21s - loss: 0.1783 - mean_absolute_error: 0.3460 - val_loss: 0.2091 - val_mean_absolute_error: 0.3564\n",
      "Epoch 52/100\n",
      " - 22s - loss: 0.1786 - mean_absolute_error: 0.3462 - val_loss: 0.2126 - val_mean_absolute_error: 0.3566\n",
      "Epoch 53/100\n",
      " - 22s - loss: 0.1780 - mean_absolute_error: 0.3454 - val_loss: 0.2015 - val_mean_absolute_error: 0.3521\n",
      "Epoch 54/100\n",
      " - 21s - loss: 0.1772 - mean_absolute_error: 0.3443 - val_loss: 0.1973 - val_mean_absolute_error: 0.3511\n",
      "Epoch 55/100\n",
      " - 21s - loss: 0.1753 - mean_absolute_error: 0.3418 - val_loss: 0.2086 - val_mean_absolute_error: 0.3546\n",
      "Epoch 56/100\n",
      " - 21s - loss: 0.1757 - mean_absolute_error: 0.3425 - val_loss: 0.2119 - val_mean_absolute_error: 0.3549\n",
      "Epoch 57/100\n",
      " - 21s - loss: 0.1751 - mean_absolute_error: 0.3415 - val_loss: 0.1994 - val_mean_absolute_error: 0.3504\n",
      "Epoch 58/100\n",
      " - 22s - loss: 0.1742 - mean_absolute_error: 0.3401 - val_loss: 0.1976 - val_mean_absolute_error: 0.3512\n",
      "Epoch 59/100\n",
      " - 21s - loss: 0.1736 - mean_absolute_error: 0.3396 - val_loss: 0.2025 - val_mean_absolute_error: 0.3498\n",
      "Epoch 60/100\n",
      " - 22s - loss: 0.1734 - mean_absolute_error: 0.3392 - val_loss: 0.2210 - val_mean_absolute_error: 0.3581\n",
      "Epoch 61/100\n",
      " - 22s - loss: 0.1735 - mean_absolute_error: 0.3391 - val_loss: 0.2097 - val_mean_absolute_error: 0.3521\n",
      "Epoch 62/100\n",
      " - 22s - loss: 0.1724 - mean_absolute_error: 0.3373 - val_loss: 0.2010 - val_mean_absolute_error: 0.3480\n",
      "Epoch 63/100\n",
      " - 23s - loss: 0.1718 - mean_absolute_error: 0.3364 - val_loss: 0.1999 - val_mean_absolute_error: 0.3478\n",
      "Epoch 64/100\n",
      " - 23s - loss: 0.1713 - mean_absolute_error: 0.3362 - val_loss: 0.2009 - val_mean_absolute_error: 0.3472\n",
      "Epoch 65/100\n",
      " - 23s - loss: 0.1702 - mean_absolute_error: 0.3342 - val_loss: 0.2042 - val_mean_absolute_error: 0.3494\n",
      "Epoch 66/100\n",
      " - 23s - loss: 0.1709 - mean_absolute_error: 0.3350 - val_loss: 0.2003 - val_mean_absolute_error: 0.3463\n",
      "Epoch 67/100\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=\"sgd\", metrics=['mae'])\n",
    "\n",
    "model.fit([train_Xception],y_train,\n",
    "          validation_data=([valid_Xception], y_valid),\n",
    "          epochs=100, batch_size=10,callbacks=[model_checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([test_Xception])\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print (y_test.shape)\n",
    "print (predictions.shape)\n",
    "print (mean_absolute_error(y_test[:], predictions[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enregistrer l'angle pour effectuer une rotation \n",
    "\n",
    "for index in range (len(predictions)):\n",
    "    \n",
    "    liste_angle.append(predictions[index][0])\n",
    "    \n",
    "d = {'name': liste_name, 'angle': liste_angle}\n",
    "df = pd.DataFrame(data=d)\n",
    "            \n",
    "df.to_csv('liste_label_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"On incline les images (aboutie à la formation de losanges) de l'angle déterminée par l'algorithme anterieur de \n",
    "détection automatique d'angles\"\"\"\n",
    "\n",
    "dim = 256\n",
    "\n",
    "j_te = 0\n",
    "\n",
    "# Open a file\n",
    "path = \"./images_translat\"\n",
    "dirs = os.listdir( path )\n",
    "\n",
    "for i in range (4):\n",
    "\n",
    "    for file in (dirs):\n",
    "        \n",
    "        if (str(file)[-4] == '.') or (str(file)[-3] == '.') or (str(file)[-5] == '.'):\n",
    "\n",
    "            file_picture =  \"./images_translat/\" + str(file)\n",
    "            #print (file_picture)   \n",
    "\n",
    "            img_open = load_img(file_picture, target_size=(dim, dim))  # this is a PIL image  \n",
    "\n",
    "\n",
    "            j_te = j_te + 1\n",
    "\n",
    "\n",
    "            img_s = img_to_array(img_open)\n",
    "\n",
    "            l = img_s.shape[0]\n",
    "            \n",
    "            # rescale angle \n",
    "            #alpha_deg = np.random.rand(1)*20 + 5\n",
    "            alpha_deg = -(labels[labels['name'] == ('predict' + str(file))].iloc[0,2] - 0.5)*50\n",
    "            \n",
    "            alpha = alpha_deg*np.pi/180\n",
    "            if (np.abs(alpha_deg)>4):\n",
    "                \n",
    "\n",
    "                x = l/(1 + np.absolute(np.sin(alpha)))\n",
    "                a = x * np.absolute(np.sin(alpha))\n",
    "                b = x * np.absolute(np.cos(alpha))\n",
    "                d = a\n",
    "                c = l - (a+b)   \n",
    "\n",
    "\n",
    "                pts = np.array([[l,int(np.around(b+c))],[int(np.around(a+c)),l],[int(np.around(c)),int(np.around(l-b))],\n",
    "                                [int(np.around(l-d)),int(np.around(c))]])\n",
    "\n",
    "                ## (1) Crop the bounding rect\n",
    "                rect = cv2.boundingRect(pts)\n",
    "                x,y,w,h = rect\n",
    "                croped = img_s[y:y+h, x:x+w].copy()\n",
    "\n",
    "                ## (2) make mask\n",
    "                pts = pts - pts.min(axis=0)\n",
    "\n",
    "                mask = np.zeros(croped.shape[:2], np.uint8)\n",
    "                cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "                ## (3) do bit-op\n",
    "                dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
    "\n",
    "                ## (4) add the white background\n",
    "                bg = np.ones_like(croped, np.uint8)*255\n",
    "                cv2.bitwise_not(bg,bg, mask=mask)\n",
    "                dst2 = bg+ dst\n",
    "\n",
    "                mat = np.ones((l,l,3))*255\n",
    "                mat[int(np.around(c))::,0:-int(np.around(c)),:] = dst2[:,:,:]\n",
    "\n",
    "                img_end = np.zeros((img_s.shape[0],img_s.shape[1]*2,3))\n",
    "\n",
    "                img_end[:,:img_end.shape[1]//2,:] = img_s[:,:,:]\n",
    "                img_end[:,img_end.shape[1]//2:,:] = mat[:,:,:]\n",
    "\n",
    "                img = array_to_img(img_end)\n",
    "\n",
    "                if (str(file)[-3:] == 'jpg' ) or (str(file)[-3:] == 'gif' )  or (str(file)[-3:] == 'JPG' ):\n",
    "\n",
    "                    img.save(\"./images_translat5/\" + str(file)) \n",
    "\n",
    "                else :\n",
    "\n",
    "                    img.save(\"./images_translat5/\" +str(file) ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
